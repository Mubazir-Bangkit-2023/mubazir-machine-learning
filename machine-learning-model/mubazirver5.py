# -*- coding: utf-8 -*-
"""mubazirver4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ud8lfCGj_3pv1TzxL4VuA10lV9d6vnVZ
"""

from google.colab import drive
drive.mount('/content/drive/')

train_dir = '/content/drive/MyDrive/dataset/Train'
test_dir = '/content/drive/MyDrive/dataset/Test'

import os

total_train = 0

for i in os.listdir(train_dir):
  total_train += len(os.listdir(train_dir+'/'+i))
  print('Total File ', i, '=', len(os.listdir(train_dir+'/'+ i)))

print(total_train)

total_test = 0

for i in os.listdir(test_dir):
  total_test += len(os.listdir(test_dir+'/'+i))
  print('Total File ', i, '=', len(os.listdir(test_dir+'/'+ i)))

print(total_test)


total = 0
total = total_train + total_test
print('Total dataset = ', total)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
def view_random_image (target_dir, target_class):
  target_folder = target_dir + target_class
  random_image = random.sample(os.listdir(target_folder),1)

  img = mpimg.imread(target_folder + '/' + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis('off')

  print(f"Ukuran gambar : {img.shape}")
  return img

img = view_random_image (train_dir, '/rottenbanana')

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers,models

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Freeze the layers of the pre-trained model
for layer in base_model.layers:
    layer.trainable = False

# Create a new model on top of the pre-trained model
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(16, activation='softmax')
])

# Print the model summary
model.summary()

# Set the training parameters
model.compile(loss = 'categorical_crossentropy',
              optimizer='adamax',
              metrics=['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

training_datagen = ImageDataGenerator(
		 rescale = 1./255,
		 brightness_range=[0.5, 1.5],
		 channel_shift_range=50.0,
		 fill_mode='nearest'
)

validation_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	train_dir,
	target_size=(150,150),
	class_mode='categorical',
  batch_size=15
)

validation_generator = validation_datagen.flow_from_directory(
	test_dir,
	target_size=(150,150),
	class_mode='categorical',
  batch_size=15
)

class stop_callback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if logs['accuracy'] and logs ['val_accuracy'] > 0.98 :
            print('\nModel berhenti ditraining!')
            self.model.stop_training = True

my_callback = stop_callback()

# Train the model
history = model.fit(train_generator,
                    epochs = 30,
                    validation_data = validation_generator,
                    callbacks=my_callback)

model.save('model.h5')

from google.colab import files

files.download('model.h5')

import matplotlib.pyplot as plt

# Plot the results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

# %matplotlib inline
uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = load_img(path, target_size=(150, 150))
  x = img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  arr = model.predict(images, batch_size=10)

# Mengambil indeks kelas dengan nilai probabilitas tertinggi
predicted_class_index = np.argmax(arr)

# Daftar label yang sesuai dengan kelas
class_labels = [
    'Fresh Apples', 'Fresh Banana', 'Fresh Cucumber', 'Fresh Okra',
    'Fresh Oranges', 'Fresh Potato', 'Fresh Tomato', 'Fresh Carrot',
    'Rotten Apples', 'Rotten Banana', 'Rotten Cucumber',
    'Rotten Okra', 'Rotten Oranges', 'Rotten Potato', 'Rotten Tomato', 'Rotten Carrot'
]

# Menentukan label
predicted_label = class_labels[predicted_class_index]

# Menampilkan hasil prediksi
print('{} is a {}'.format(fn, predicted_label))